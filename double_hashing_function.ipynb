{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing pseudonymised IDs using double hashing\n",
    "\n",
    "This notebook pseudonymises a dataset of synthetic IDs using double hashing with SHA3-512 and SHA3-256 encoding of the IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dummy dataset for testing\n",
    "\n",
    "Produce a synthetic dataset with 1 million rows and 2 columns:\n",
    "* Column 0 is a numerical identifier of 7 digits\n",
    "* Column 1 is a binary string variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id gender\n",
      "0  7260232      f\n",
      "1  3316241      m\n",
      "2  1427566      f\n",
      "3  4825511      m\n",
      "4  8715645      f\n",
      "Dummy dataset created\n"
     ]
    }
   ],
   "source": [
    "n = 1000000\n",
    "gen = ['m', 'f']\n",
    "id_list = list()\n",
    "gen_list = list()\n",
    "for i in range(0,n):\n",
    "    ids = rnd.randrange(1000000, 9999999)\n",
    "    id_list.append(ids)\n",
    "    gen_choice = rnd.choice(gen)\n",
    "    gen_list.append(gen_choice)\n",
    "d_dict = {'id': id_list, 'gender': gen_list}\n",
    "df = pd.DataFrame(d_dict)\n",
    "print(df.head())\n",
    "print('Dummy dataset created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of unique identifiers in the dummy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique identifiers in the dataset is 946507\n"
     ]
    }
   ],
   "source": [
    "uni_id = df['id'].unique()\n",
    "print('The number of unique identifiers in the dataset is ' + str(len(uni_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any rows containing duplicate identifiers from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate identifiers have been removed from the dataset\n"
     ]
    }
   ],
   "source": [
    "df_uni = df.drop_duplicates(subset=['id'], keep = 'first').copy(deep=True)\n",
    "print('Duplicate identifiers have been removed from the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the values in the id column to string objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The contents of the id column has been converted to string objects\n"
     ]
    }
   ],
   "source": [
    "df_uni['id'] = df_uni['id'].astype(str)\n",
    "print('The contents of the id column has been converted to string objects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions for pseudonymisation using double hashing\n",
    "\n",
    "These functions will pseudonymise unique identifiers in a dataset to provide a master list.\n",
    "* The process first converts each identifier to uft-8 format then encrypts each identifier using a sha3_512 key.\n",
    "* This value is then divided by 10^n where n is the number of digits to return which must be less than 512. The smaller the number of digits returned the greater the likelihood of duplicate values which will increase processing time.\n",
    "* This process is then repeated returning a number of digits equal to or if specified greater than that specified in the first hashing process.\n",
    "* Where duplicates are produced the hashing process will be completed until no duplicates remain.\n",
    "* Processing time will depend on the number of identifiers being pseudonymised and the number of digits being returned. To reduce processing time, the more identifiers being returned the greater the number of digits being returned should be.\n",
    "\n",
    "This method of double hashing is GDPR compliant and non-reversible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode ID using sha encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df, i, org_col, n):\n",
    "    '''\n",
    "    Encode an ID using SHA3_512 encryption.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe contained the ID to be encoded\n",
    "    i : integer\n",
    "        Row/Index of the ID to be encoded\n",
    "    org_col: string\n",
    "        Name of the column with the ID to be encoded\n",
    "    n : integer\n",
    "        Desired length of the new ID\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h_id : string\n",
    "        Newly encoded ID\n",
    "    '''\n",
    "    # Convert ID to UTF-8 format, encrypt using SHA3_512 key, then divide by\n",
    "    # 10^n where n is the number of digits to return - smaller number means\n",
    "    # greater likelihood of duplicate values which will increase processing time\n",
    "    h_id = int(hashlib.sha3_512(\n",
    "        df.loc[df.index[i], org_col].encode(\"utf-8\")).hexdigest(),16) % (10 ** n)\n",
    "    return h_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reencode(df, i, org_col, n):\n",
    "    '''\n",
    "    Encode an ID using SHA3_256 encryption.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe contained the ID to be encoded\n",
    "    i : integer\n",
    "        Row/Index of the ID to be encoded\n",
    "    org_col: string\n",
    "        Name of the column with the ID to be encoded\n",
    "    n : integer\n",
    "        Desired length of the new ID\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h_id : string\n",
    "        Newly encoded ID\n",
    "    '''\n",
    "    # Convert ID to UTF-8 format, encrypt using SHA3_512 key, then divide by\n",
    "    # 10^n where n is the number of digits to return - smaller number means\n",
    "    # greater likelihood of duplicate values which will increase processing time\n",
    "    h_id = int(hashlib.sha3_256(\n",
    "        df.loc[df.index[i], org_col].encode(\"utf-8\")).hexdigest(),16) % (10 ** n)\n",
    "    return h_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over ID's, run encode function, append to list and concatenate with dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_process(df, org_col, n, new_col):\n",
    "    '''\n",
    "    Create a new column with encoded IDs and add to the dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe with IDs to be pseudonymised\n",
    "    org_col : string\n",
    "        Original column of IDs\n",
    "    n : integer\n",
    "        Desired length of the pseudonymised IDs\n",
    "    new_col : string\n",
    "        Name of new column that will contain the pseudonymised IDs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "        Dataframe with new column of pseudonymised IDs added\n",
    "    '''\n",
    "    # Create an empty list to store the IDs\n",
    "    hash_id_list = list()\n",
    "\n",
    "    # Iterate over the IDs\n",
    "    for i in range(len(df)):\n",
    "        # Generate a pseudonymised ID and save to list\n",
    "        h_id = encode(df, i, org_col, n)\n",
    "        hash_id_list.append(h_id)\n",
    "\n",
    "    # Create a new column in the dataframe with the pseudonymised IDs\n",
    "    df[new_col] = hash_id_list\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-encode a duplicate and replace inplace in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reencode_duplicate(df, i, org_col, tar_col, n):\n",
    "    '''\n",
    "    Replace an ID in the dataframe with a newly encoded ID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe containing the ID to be replaced\n",
    "    i : integer\n",
    "        Row/index of the ID to be replaced\n",
    "    org_col : string\n",
    "        Name of column with the original ID, that was encoded to produce the\n",
    "        ID in tar_col\n",
    "    tar_col : string\n",
    "        Name of column with the ID to be replaced\n",
    "    n : integer\n",
    "        Desired length of the pseudonymised ID\n",
    "    '''\n",
    "    # Re-encode ID\n",
    "    new_hash = reencode(df, i, org_col,  n)\n",
    "    # Replace that ID in the dataframe\n",
    "    df.at[i, tar_col] = new_hash\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find indexes of duplicate encoded ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(df, col):\n",
    "    '''\n",
    "    Find index of duplicate encoded IDs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe with the IDs\n",
    "    col : string\n",
    "        Name of the column with the IDs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dup_ind : boolean series\n",
    "        Series where True if ID is duplicate\n",
    "    dup_count : integer\n",
    "        Number of duplicate IDs in the dataframe\n",
    "    '''\n",
    "    # Get indices of duplicate IDs\n",
    "    dup_ind = df.duplicated(subset=[col])\n",
    "    # Get count of duplicate IDs\n",
    "    dup_count = dup_ind.sum()\n",
    "    return dup_ind, dup_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run check for duplicate encoded ID's and re-encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_check(df, org_col, tar_col, n):\n",
    "    '''\n",
    "    Check for duplicate encoded IDs, and rencode (using the original ID). Repeat\n",
    "    until there are no duplicates remaining.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe with the original and pseudonymised IDs\n",
    "    org_col : string\n",
    "        Name of column with the original IDs that were just pseudonymised\n",
    "    targ_col : string\n",
    "        Name of column of IDs within which we are checking for duplicates\n",
    "    n : integer\n",
    "        Desired length of pseudonymised IDs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "        Dataframe with duplicate IDs replaced\n",
    "    '''\n",
    "    # Find the indices and number of duplicates\n",
    "    dup_ind, dup_count = find_duplicates(df, tar_col)\n",
    "\n",
    "    # If there are any present...\n",
    "    while dup_count > 0:\n",
    "\n",
    "        # Print count of duplicate indices\n",
    "        print(dup_count)\n",
    "        # print(dup_ind)\n",
    "\n",
    "        # Reduce length of produced ID by 1\n",
    "        n = n - 1\n",
    "\n",
    "        # Loop through the indices and re-encode\n",
    "        for i in range(len(dup_ind)):\n",
    "            if dup_ind[i] == True:\n",
    "                df = reencode_duplicate(df, i, org_col, tar_col, n)\n",
    "\n",
    "        # Get indices and counts of any remaining duplicates\n",
    "        dup_ind, dup_count = find_duplicates(df, tar_col)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert column to string type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_to_string(df, id_col):\n",
    "    '''\n",
    "    Convert column data type to string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe containing the column to be converted\n",
    "    id_col : string\n",
    "        Name of the column to be converted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "        Dataframe with converted column\n",
    "    '''\n",
    "    df[id_col] = df[id_col].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the functions required for double hash encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_hash_pseudo(df, id_col, n1):\n",
    "    '''\n",
    "    Pseudonymise IDs using double-hashing\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Dataframe with the IDs to be pseudonymised\n",
    "    id_col : string\n",
    "        Name of the ID column to be pseudonymised\n",
    "    n1 : integer\n",
    "        Desired length of the final pseudonymised IDs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_h2_rev : pandas dataframe\n",
    "        Dataframe with two new columns (in-progress and final set of pseudo IDs)\n",
    "    '''\n",
    "    # Set names for the ID columns\n",
    "    h1_col = 'h_id'\n",
    "    h2_col = 'h_id_two'\n",
    "\n",
    "    # Convert original ID column to string\n",
    "    df = col_to_string(df, id_col)\n",
    "\n",
    "    # Add a new column with pseudymised IDs to the dataframe\n",
    "    df_h1 = hash_process(df, id_col, n1, h1_col)\n",
    "    # print(df_h1.head())\n",
    "    # print(len(df_h1))\n",
    "\n",
    "    # Run a duplicate check\n",
    "    df_h1_rev = duplicate_check(df_h1, id_col, h1_col, n1)\n",
    "\n",
    "    # Print status update\n",
    "    print(len(df_h1_rev))\n",
    "    print('Hash one complete')\n",
    "\n",
    "    # Repeat process a second time\n",
    "    df = col_to_string(df, h1_col)\n",
    "    df_h2 = hash_process(df_h1_rev, h1_col, n1, h2_col)\n",
    "    df_h2_rev = duplicate_check(df_h2, h1_col, h2_col, n1)\n",
    "\n",
    "    return df_h2_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the double hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53493\n",
      "2005\n",
      "253\n",
      "34\n",
      "5\n",
      "1000000\n",
      "Hash one complete\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "df_pseudo = double_hash_pseudo(df, 'id', 12)\n",
    "print(len(df_pseudo))\n",
    "# print(df_pseudo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id gender          h_id      h_id_two\n",
      "0       7260232      f  232241645964  347719229216\n",
      "1       3316241      m  106410238251  191104966042\n",
      "2       1427566      f  402590042291   87835444441\n",
      "3       4825511      m  707826129375  709888269764\n",
      "4       8715645      f  328794091852  177046366543\n",
      "...         ...    ...           ...           ...\n",
      "999995  9709425      m  509706073734  701117790328\n",
      "999996  7975837      m  613809405124   91982678534\n",
      "999997  8648401      m  974823974511  259188951056\n",
      "999998  3590847      m   65858948736  200306710672\n",
      "999999  1673734      f   18167887387  540251442555\n",
      "\n",
      "[1000000 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25928"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_pseudo)\n",
    "df_pseudo['h_id_two'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the hashed ID's to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pseudo.to_csv('pseudo_out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
