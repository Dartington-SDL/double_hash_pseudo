{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dummy dataset for testing\n",
    "Contains 1 million rows and 2 columns\n",
    "Column 0 is a numerical identifier of 7 digits\n",
    "Column 1 is a binary string variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "gen = ['m', 'f']\n",
    "id_list = list()\n",
    "gen_list = list()\n",
    "for i in range(0,n):\n",
    "    ids = rnd.randrange(1000000, 9999999)\n",
    "    id_list.append(ids)\n",
    "    gen_choice = rnd.choice(gen)\n",
    "    gen_list.append(gen_choice)\n",
    "d_dict = {'id': id_list, 'gender': gen_list}\n",
    "df = pd.DataFrame(d_dict)\n",
    "print(df.head())\n",
    "print('Dummy dataset created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the number of unique identifiers in the dummy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_id = df['id'].unique()\n",
    "print('The number of unique identifiers in the dataset is ' + str(len(uni_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove any rows containing duplicate identifiers from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni = df.drop_duplicates(subset=['id'], keep = 'first').copy(deep=True)\n",
    "print('Duplicate identifiers have been removed from the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the values in the id column to string objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni['id'] = df_uni['id'].astype(str)\n",
    "print('The contents of the id column has been converted to string objects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for pseudonymisation using double hashing\n",
    "This function will pseudonymise unique identifiers in a dataset to provide a master list\n",
    "The process first converts each identifier to uft-8 format then encrypts each identifier using a sha3_512 key. This value is then divided by 10^n where n is the number of digits to return which must be less than 512. The smaller the number of digits returned the greater the likelihood of duplicate values which will increase processing time.\n",
    "This process is then repeated returning a number of digits equal to or if specified greater than that specified in the first hashing process.\n",
    "Where duplicates are produced the hashing process will be completed until no duplicates remain.\n",
    "Processing time will depend on the number of identifiers being pseudonymised and the number of digits being returned. To reduce processing time, the more identifiers being returned the greater the number of digits being returned should be.\n",
    "This method of double hashing is GDPR compliant and non-reversable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode ID using sha encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df, i, org_col, n):\n",
    "    h_id = int(hashlib.sha3_512(df.loc[df.index[i], org_col].encode(\"utf-8\")).hexdigest(),16) % (10 ** n)\n",
    "    return h_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reencode(df, i, org_col, n):\n",
    "    h_id = int(hashlib.sha3_256(df.loc[df.index[i], org_col].encode(\"utf-8\")).hexdigest(),16) % (10 ** n)\n",
    "    return h_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over ID's, run encode function, append to list and concatenate with dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_process(df, org_col, n, new_col):\n",
    "    hash_id_list = list()\n",
    "    for i in range(len(df)):\n",
    "        h_id = encode(df, i, org_col, n)\n",
    "        hash_id_list.append(h_id)\n",
    "    df[new_col] = hash_id_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-encode a duplicate and replace inplace in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reencode_duplicate(df, i, org_col, tar_col, n):\n",
    "    new_hash = reencode(df, i, org_col,  n)\n",
    "    df.at[i, tar_col] = new_hash\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find indexes of duplicate encoded ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(df, col):\n",
    "    dup_ind = df.duplicated(subset=[col])\n",
    "    dup_count = dup_ind.sum()\n",
    "    return dup_ind, dup_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run check for duplicate encoded ID's and re-encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_check(df, org_col, tar_col, n):\n",
    "    dup_ind, dup_count = find_duplicates(df, tar_col)\n",
    "    while dup_count > 0:\n",
    "        print(dup_count)\n",
    "        # print(dup_ind)\n",
    "        n = n - 1\n",
    "        for i in range(len(dup_ind)):\n",
    "            if dup_ind[i] == True:\n",
    "                df = reencode_duplicate(df, i, org_col, tar_col, n)\n",
    "        dup_ind, dup_count = find_duplicates(df, tar_col)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert column to string type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_to_string(df, id_col):\n",
    "    df[id_col] = df[id_col].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the functions required for double hash encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_hash_pseudo(df, id_col, n1):\n",
    "    h1_col = 'h_id'\n",
    "    h2_col = 'h_id_two'\n",
    "    df = col_to_string(df, id_col)\n",
    "    df_h1 = hash_process(df, id_col, n1, h1_col)\n",
    "    # print(df_h1.head())\n",
    "    # print(len(df_h1))\n",
    "    df_h1_rev = duplicate_check(df_h1, id_col, h1_col, n1)\n",
    "    print(len(df_h1_rev))\n",
    "    print('Hash one complete')\n",
    "    df = col_to_string(df, h1_col)\n",
    "    df_h2 = hash_process(df_h1_rev, h1_col, n1, h2_col)\n",
    "    df_h2_rev = duplicate_check(df_h2, h1_col, h2_col, n1)\n",
    "    return df_h2_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the double hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pseudo = double_hash_pseudo(df, 'id', 12)\n",
    "print(len(df_pseudo))\n",
    "# print(df_pseudo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pseudo)\n",
    "df_pseudo['h_id_two'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the hashed ID's to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pseudo.to_csv('pseudo_out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
